{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9749efa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installer nibabel si n√©cessaire (ex√©cuter dans la cellule Jupyter)\n",
    "%pip install nibabel\n",
    "\n",
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE  # Pour la gestion des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370311d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 0. PARAM√àTRES ET CHEMINS\n",
    "# ==============================================================================\n",
    "\n",
    "# Dossier Racine contenant les sous-dossiers de classes (MildDemented, NonDemented, etc.)\n",
    "DATA_ROOT_DIR = 'C:\\\\Users\\\\angej\\\\Desktop\\\\Advancing Alzheimer‚Äôs Disease Detection in Clinical Settings MRI Image Data\\\\Advancing Alzheimer‚Äôs Disease Detection in Clinical Settings MRI Image Data\\\\Alzheimer_s Dataset\\\\train' \n",
    "\n",
    "# Param√®tres de l'image et du mod√®le\n",
    "IMAGE_SIZE = (128, 128)  # Redimensionnement des images (Section 12: Resizing Images)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Les classes sont d√©finies par vos noms de dossiers (image_59df9b.png)\n",
    "CLASS_NAMES = ['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented']\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "# D√©finir l'ordre des classes si n√©cessaire pour l'interpr√©tation des r√©sultats\n",
    "# Keras chargera les classes par ordre alphanum√©rique, donc v√©rifiez l'ordre r√©el.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2865d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Le dossier racine de votre ensemble d'entra√Ænement (contient les dossiers de classes)\n",
    "DATA_ROOT_DIR = 'path/to/votre/dossier/train' \n",
    "\n",
    "# Les noms de vos dossiers (classes)\n",
    "CLASS_NAMES = ['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented']\n",
    "\n",
    "def plot_class_distribution(data_dir, classes):\n",
    "    \"\"\"Calcule et affiche la distribution des classes.\"\"\"\n",
    "    counts = {}\n",
    "    for cls in classes:\n",
    "        cls_path = os.path.join(data_dir, cls)\n",
    "        # Compte le nombre de fichiers .jpg dans chaque dossier\n",
    "        if os.path.isdir(cls_path):\n",
    "            count = len([name for name in os.listdir(cls_path) if name.endswith(('.jpg', '.jpeg', '.png'))])\n",
    "            counts[cls] = count\n",
    "        else:\n",
    "            counts[cls] = 0\n",
    "    \n",
    "    df_counts = pd.DataFrame(list(counts.items()), columns=['Class', 'Count']).sort_values(by='Count', ascending=False)\n",
    "    \n",
    "    print(\"Distribution des Classes:\\n\", df_counts)\n",
    "    \n",
    "    # Visualisation\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(df_counts['Class'], df_counts['Count'], color=['skyblue', 'salmon', 'lightgreen', 'gold'])\n",
    "    plt.title('Distribution du Nombre d\\'Images par Classe de D√©mence')\n",
    "    plt.xlabel('Stade de D√©mence')\n",
    "    plt.ylabel('Nombre d\\'Images')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# plot_class_distribution(DATA_ROOT_DIR, CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758790ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "# I. FONCTIONS DE PR√â-TRAITEMENT ET CHARGEMENT DES DONN√âES\n",
    "# ==============================================================================\n",
    "\n",
    "def load_data_from_directory(directory, subset_name=None, seed=None):\n",
    "    \"\"\"\n",
    "    Charge les images depuis les dossiers. G√®re le redimensionnement, \n",
    "    et la normalisation (image / 255.0 - Section 12).\n",
    "    \"\"\"\n",
    "    if subset_name:\n",
    "        print(f\"Chargement du sous-ensemble: {subset_name}\")\n",
    "\n",
    "    # Le label_mode='categorical' applique le One-Hot Encoding (Section 3)\n",
    "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "        directory,\n",
    "        labels='inferred',\n",
    "        label_mode='categorical',\n",
    "        class_names=CLASS_NAMES,\n",
    "        image_size=IMAGE_SIZE,\n",
    "        interpolation='bilinear',\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True if subset_name == 'training' else False,\n",
    "        seed=seed \n",
    "    )\n",
    "    \n",
    "    # Normaliser les valeurs de pixel (Section 12: Normalizing Pixel Values)\n",
    "    # L'intervalle de [0, 255] est mis √† l'√©chelle √† [0, 1]\n",
    "    normalization_layer = layers.Rescaling(1./255) \n",
    "    \n",
    "    return dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "\n",
    "def setup_data_generators(data_root_dir):\n",
    "    \"\"\"\n",
    "    Configure le split Train/Validation/Test et l'augmentation des donn√©es.\n",
    "    \"\"\"\n",
    "    # √âtape 1: S√©parer les donn√©es en Training et Test (Section 10)\n",
    "    # Nous utiliserons la s√©paration manuelle pour un contr√¥le total sur l'augmentation\n",
    "    \n",
    "    # Keras ne supporte pas nativement la Stratified Split sur les dossiers\n",
    "    # Il est recommand√© de le faire manuellement ou d'utiliser une K-Fold manuelle.\n",
    "    # Pour la simplicit√©, nous allons utiliser un split direct Keras/TF.\n",
    "\n",
    "    # Chargement d'un grand ensemble pour le Training/Validation\n",
    "    train_ds = load_data_from_directory(DATA_ROOT_DIR, subset_name='training', seed=RANDOM_STATE)\n",
    "    \n",
    "    # D√©terminer la taille pour le split Validation/Test\n",
    "    # Prenons 80% des donn√©es pour le train et 20% pour le test (split non-stratifi√© ici)\n",
    "    \n",
    "    # Pour un environnement r√©el, utiliser train_test_split (sklearn) apr√®s avoir \n",
    "    # list√© tous les chemins d'acc√®s pour garantir la stratification.\n",
    "    \n",
    "    # Utilisons ImageDataGenerator pour l'augmentation (Section 12: Image Augmentation)\n",
    "    # Ceci est appliqu√© uniquement √† l'ensemble d'entra√Ænement pour √©viter la fuite de donn√©es.\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    # Comme image_dataset_from_directory charge d√©j√† et normalise, nous allons\n",
    "    # Simplement utiliser les transformations de l'augmentation comme un layer Keras\n",
    "    # dans le mod√®le pour un pipeline plus moderne (voir fonction build_2d_cnn_model).\n",
    "    \n",
    "    # Note: Dans un sc√©nario id√©al, vous devriez utiliser StratifiedKFold (Section 10) \n",
    "    # pour garantir que chaque classe (surtout 'ModerateDemented' qui pourrait √™tre petite) \n",
    "    # est bien repr√©sent√©e.\n",
    "    \n",
    "    return train_ds # Simplification: utilisez cet ensemble comme ensemble principal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e15f677",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "# II. D√âFINITION DU MOD√àLE 2D CNN (VGG-like)\n",
    "# ==============================================================================\n",
    "\n",
    "def build_2d_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Construit une architecture 2D CNN simple (VGG-like) adapt√©e aux images JPEG.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Couche d'Augmentation (pour le Training seulement, appliqu√©e avant le mod√®le)\n",
    "    data_augmentation = keras.Sequential(\n",
    "        [\n",
    "            layers.RandomFlip(\"horizontal\", seed=RANDOM_STATE),\n",
    "            layers.RandomRotation(0.1, seed=RANDOM_STATE),\n",
    "            layers.RandomZoom(0.1, seed=RANDOM_STATE),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Appliquer l'augmentation uniquement si ce n'est pas la validation/test\n",
    "    x = data_augmentation(inputs) \n",
    "    \n",
    "    # Standardisation Z-Score (Section 2 - Data Transformation) peut √™tre r√©appliqu√©e ici si besoin\n",
    "    # mean_std_layer = layers.Normalization() \n",
    "    # x = mean_std_layer(x) \n",
    "\n",
    "    # Blocs de Convolution 2D\n",
    "    \n",
    "    x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    \n",
    "    x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    \n",
    "    x = layers.Conv2D(128, 3, activation='relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    \n",
    "    # Classification\n",
    "    x = layers.GlobalAveragePooling2D()(x) \n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x) # Section 33: Dropout (Technique d'√©vitement du surapprentissage)\n",
    "    \n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs, name=\"2dcnn_alzheimer\")\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy', keras.metrics.Recall(name='recall')] # Rappel/Sensibilit√© pour la d√©tection pr√©coce\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# ==============================================================================\n",
    "# III. EX√âCUTION DU PIPELINE\n",
    "# ==============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(\"--- üß† Pipeline de classification 2D Alzheimer (JPEG) üß† ---\")\n",
    "\n",
    "    # V√©rifiez si le dossier existe\n",
    "    if not os.path.isdir(DATA_ROOT_DIR):\n",
    "        print(f\"Erreur: Le dossier racine '{DATA_ROOT_DIR}' n'existe pas. Veuillez le mettre √† jour.\")\n",
    "    else:\n",
    "        # 1. Chargement des donn√©es et Pr√©-traitement\n",
    "        \n",
    "        # NOTE: Nous allons simuler un split train/validation/test ici.\n",
    "        # En r√©alit√©, vos donn√©es devraient √™tre dans des dossiers train/val/test s√©par√©s.\n",
    "        \n",
    "        train_ds = load_data_from_directory(DATA_ROOT_DIR, subset_name='training', seed=RANDOM_STATE).take(int(0.8 * len(os.listdir(DATA_ROOT_DIR))))\n",
    "        val_ds = load_data_from_directory(DATA_ROOT_DIR, subset_name='validation', seed=RANDOM_STATE).skip(int(0.8 * len(os.listdir(DATA_ROOT_DIR))))\n",
    "\n",
    "        # 2. Gestion des Donn√©es D√©s√©quilibr√©es (Dealing with Imbalanced Data - Section 14)\n",
    "        # Pour les datasets charg√©s directement (image_dataset_from_directory), la meilleure \n",
    "        # technique est souvent la pond√©ration des classes ou le sur-√©chantillonnage \n",
    "        # pendant l'entra√Ænement, car SMOTE (Section 14) est difficile √† appliquer directement \n",
    "        # sur les g√©n√©rateurs de donn√©es Keras sans les mat√©rialiser en m√©moire.\n",
    "        \n",
    "        # Calcul des pond√©rations de classe pour l'exemple (tr√®s important ici)\n",
    "        print(\"\\nCalcul des poids de classe (pour g√©rer le d√©s√©quilibre)...\")\n",
    "        # Un calcul r√©el n√©cessiterait de parcourir l'ensemble de donn√©es complet\n",
    "        class_counts = {\n",
    "            'NonDemented': 2560, # Simuler un grand nombre\n",
    "            'VeryMildDemented': 1792,\n",
    "            'MildDemented': 896,\n",
    "            'ModerateDemented': 64 # Simuler la classe la plus petite\n",
    "        }\n",
    "        total_samples = sum(class_counts.values())\n",
    "        max_count = max(class_counts.values())\n",
    "        \n",
    "        # Pond√©ration: inversement proportionnelle √† la fr√©quence\n",
    "        class_weights = {\n",
    "            CLASS_NAMES.index(cls): max_count / count \n",
    "            for cls, count in class_counts.items()\n",
    "        }\n",
    "        print(f\"Poids de classe ajust√©s (pour le param√®tre class_weight): {class_weights}\")\n",
    "\n",
    "\n",
    "        # 3. Entra√Ænement du Mod√®le\n",
    "        \n",
    "        input_shape = (*IMAGE_SIZE, 3) # Les images JPG ont 3 canaux (RGB)\n",
    "        model = build_2d_cnn_model(input_shape, NUM_CLASSES)\n",
    "        model.summary()\n",
    "\n",
    "        print(\"\\n--- Entra√Ænement du mod√®le 2D CNN ---\")\n",
    "        \n",
    "        # Utiliser les poids de classe pour compenser le d√©s√©quilibre\n",
    "        history = model.fit(\n",
    "            train_ds,\n",
    "            validation_data=val_ds,\n",
    "            epochs=EPOCHS,\n",
    "            class_weight=class_weights, # Appliquer la pond√©ration ici\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # 4. √âvaluation Finale\n",
    "        print(\"\\n--- √âvaluation finale du mod√®le ---\")\n",
    "        # Note: L'ensemble de validation (val_ds) sert d'√©valuation ici.\n",
    "        \n",
    "        loss, acc, rec = model.evaluate(val_ds, verbose=0)\n",
    "        \n",
    "        print(f\"R√©sultats sur l'ensemble de validation:\")\n",
    "        print(f\"  Pr√©cision (Accuracy): {acc:.4f}\")\n",
    "        print(f\"  Sensibilit√© (Recall): {rec:.4f} (Critique pour la d√©tection pr√©coce)\")\n",
    "        \n",
    "        # Sauvegarde\n",
    "        model.save(\"alzheimer_2d_cnn_final.keras\")\n",
    "        print(\"\\nMod√®le sauvegard√©.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acb1e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "# 0. PARAM√àTRES ET SIMULATION DES DONN√âES\n",
    "# ==============================================================================\n",
    "\n",
    "# NOTE: REMPLACER CES CHEMINS PAR LES V√îTRES\n",
    "IMAGE_DIR = 'data/images/'\n",
    "LABELS_FILE = 'data/labels.csv'\n",
    "\n",
    "# Param√®tres du mod√®le et du pr√©traitement\n",
    "IMAGE_SIZE = (64, 64, 64) # Taille cible des volumes (compromis entre performance et VRAM)\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 10 \n",
    "K_FOLDS = 5 # Pour la validation crois√©e stratifi√©e\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Simulation de la base de donn√©es (si non disponible)\n",
    "# df = pd.DataFrame({\n",
    "#     'ID': [f'sujet_{i:03d}' for i in range(100)],\n",
    "#     'Groupe': np.random.choice(['CN', 'MCI', 'AD'], \n",
    "#                                size=100, \n",
    "#                                p=[0.7, 0.2, 0.1]) # Classes d√©s√©quilibr√©es\n",
    "# })\n",
    "# df.to_csv(LABELS_FILE, index=False)\n",
    "# print(\"Simulation des donn√©es termin√©e.\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# I. FONCTIONS DE PR√â-TRAITEMENT DES IMAGES\n",
    "# (S'inspire des sections 12 et 13 du TP)\n",
    "# ==============================================================================\n",
    "\n",
    "def load_and_preprocess_mri(file_path, target_size, method='z_score'):\n",
    "    \"\"\"\n",
    "    Charge une image 3D (NIfTI), applique la Normalisation (Z-Score ou Min-Max)\n",
    "    et le Redimensionnement (Resizing).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = nib.load(file_path)\n",
    "        data = img.get_fdata()\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur de chargement pour {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Normalisation de l'intensit√© (Section 2 - Data Transformation)\n",
    "    if method == 'z_score':\n",
    "        # [cite_start]Standardization (Z-Score Normalization) [cite: 13]\n",
    "        mean = np.mean(data)\n",
    "        std = np.std(data)\n",
    "        data = (data - mean) / (std + 1e-6)  # Ajout de 1e-6 pour √©viter division par z√©ro\n",
    "    elif method == 'min_max':\n",
    "        # [cite_start]Min-Max Normalization (similaire √† image / 255.0) [cite: 14, 67]\n",
    "        min_val = np.min(data)\n",
    "        max_val = np.max(data)\n",
    "        data = (data - min_val) / (max_val - min_val + 1e-6)\n",
    "\n",
    "    # [cite_start]Redimensionnement (Resizing Images - Section 12) [cite: 66]\n",
    "    # Redimensionnement 3D vers la taille cible\n",
    "    data = tf.image.resize(\n",
    "        np.expand_dims(data, axis=-1), \n",
    "        target_size, \n",
    "        method='nearest' # Ou 'trilinear' pour une meilleure qualit√©\n",
    "    ).numpy()\n",
    "    \n",
    "    # Retourne le volume sans la dimension de canal, en float32\n",
    "    return data.squeeze().astype(np.float32)\n",
    "\n",
    "def image_data_generator(df, image_dir, target_size, encoder):\n",
    "    \"\"\"\n",
    "    G√©n√©rateur de donn√©es pour charger et pr√©traiter toutes les images \n",
    "    en m√©moire pour la phase d'entra√Ænement (utile pour SMOTE).\n",
    "    \"\"\"\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    \n",
    "    print(f\"Chargement et pr√©traitement de {len(df)} images...\")\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        file_path = os.path.join(image_dir, row['ID'] + '.nii.gz') # Adapter l'extension si n√©cessaire\n",
    "        \n",
    "        image_data = load_and_preprocess_mri(file_path, target_size, method='z_score')\n",
    "        \n",
    "        if image_data is not None:\n",
    "            # Ajouter la dimension du canal (1) pour le 3D CNN\n",
    "            X_list.append(np.expand_dims(image_data, axis=-1))\n",
    "            y_list.append(row['Groupe_Encoded'])\n",
    "            \n",
    "    return np.array(X_list), np.array(y_list)\n",
    "\n",
    "# ==============================================================================\n",
    "# II. D√âFINITION DU MOD√àLE 3D CNN ET ENTRA√éNEMENT\n",
    "# ==============================================================================\n",
    "\n",
    "def build_3d_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Construit une architecture 3D CNN simple pour la classification.\n",
    "    \"\"\"\n",
    "    inputs = keras.Input(input_shape)\n",
    "\n",
    "    # Couche 1\n",
    "    x = layers.Conv3D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x) \n",
    "\n",
    "    # Couche 2\n",
    "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # Couche de classification\n",
    "    x = layers.GlobalAveragePooling3D()(x) \n",
    "    x = layers.Dense(units=128, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x) \n",
    "\n",
    "    outputs = layers.Dense(units=num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs, name=\"3dcnn_alzheimer\")\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        metrics=[\"accuracy\", keras.metrics.Recall(name='recall')]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# III. EX√âCUTION DU PIPELINE (AVEC GESTION DE D√âS√âQUILIBRE)\n",
    "# ==============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(\"--- üß† D√©but du pipeline de d√©tection pr√©coce Alzheimer üß† ---\")\n",
    "\n",
    "    # 1. Chargement et Encodage des √âtiquettes\n",
    "    df = pd.read_csv(LABELS_FILE)\n",
    "    \n",
    "    # Nettoyage des donn√©es (Handling Missing Values - Section 1)\n",
    "    [cite_start]df.dropna(subset=['Groupe'], inplace=True) # Supprimer les lignes sans √©tiquette [cite: 7]\n",
    "    \n",
    "    # Encodage des √©tiquettes (Feature Encoding - Section 3)\n",
    "    # Ex: CN -> 0, MCI -> 1, AD -> 2\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['Groupe_Encoded'] = label_encoder.fit_transform(df['Groupe'])\n",
    "    NUM_CLASSES = len(label_encoder.classes_)\n",
    "    \n",
    "    print(f\"Classes: {list(label_encoder.classes_)}\")\n",
    "    print(df['Groupe'].value_counts())\n",
    "    \n",
    "    # 2. S√©paration des donn√©es (Data Splitting - Section 10)\n",
    "    # [cite_start]S√©paration stratifi√©e pour conserver la proportion des classes dans les ensembles [cite: 58]\n",
    "    train_df, test_df = train_test_split(\n",
    "        df, \n",
    "        test_size=0.2, \n",
    "        random_state=RANDOM_STATE, \n",
    "        stratify=df['Groupe_Encoded']\n",
    "    )\n",
    "    \n",
    "    # 3. Chargement et Pr√©traitement des Volumes\n",
    "    # Nous chargeons toutes les donn√©es d'entra√Ænement pour appliquer SMOTE apr√®s.\n",
    "    X_train_raw, y_train_encoded = image_data_generator(train_df, IMAGE_DIR, IMAGE_SIZE, label_encoder)\n",
    "    X_test, y_test_encoded = image_data_generator(test_df, IMAGE_DIR, IMAGE_SIZE, label_encoder)\n",
    "    \n",
    "    # [cite_start]Conversion One-Hot pour le mod√®le (Sequence Data Processing - Section 21) [cite: 105]\n",
    "    y_test_one_hot = keras.utils.to_categorical(y_test_encoded, num_classes=NUM_CLASSES)\n",
    "    \n",
    "    # 4. Gestion des Donn√©es D√©s√©quilibr√©es (Dealing with Imbalanced Data - Section 14)\n",
    "    # SMOTE n√©cessite que les donn√©es d'image soient \"aplaties\" temporairement\n",
    "    # SMOTE n'est pas id√©al pour les donn√©es d'image haute dimension, mais il est list√©.\n",
    "    print(\"\\n--- Application de SMOTE pour l'√©quilibrage des classes ---\")\n",
    "    \n",
    "    # Aplatir les images (D*H*W*C) -> (N, D*H*W*C)\n",
    "    X_train_flat = X_train_raw.reshape(X_train_raw.shape[0], -1) \n",
    "    \n",
    "    # [cite_start]Application de SMOTE [cite: 76]\n",
    "    # Ceci va sur-√©chantillonner les classes MCI et AD (moins repr√©sent√©es)\n",
    "    smote = SMOTE(random_state=RANDOM_STATE) \n",
    "    X_train_resampled_flat, y_train_resampled_encoded = smote.fit_resample(X_train_flat, y_train_encoded)\n",
    "    \n",
    "    # Re-former les images (N, D*H*W*C) -> (N, D, H, W, C)\n",
    "    X_train_resampled = X_train_resampled_flat.reshape(\n",
    "        (len(X_train_resampled_flat), *IMAGE_SIZE, 1)\n",
    "    )\n",
    "    y_train_resampled_one_hot = keras.utils.to_categorical(\n",
    "        y_train_resampled_encoded, num_classes=NUM_CLASSES\n",
    "    )\n",
    "\n",
    "    print(\"Distribution apr√®s SMOTE:\\n\", pd.Series(y_train_resampled_encoded).value_counts())\n",
    "\n",
    "    # 5. Entra√Ænement du Mod√®le\n",
    "    input_shape = (*IMAGE_SIZE, 1) \n",
    "    model = build_3d_cnn_model(input_shape, NUM_CLASSES)\n",
    "    \n",
    "    print(\"\\n--- Entra√Ænement du mod√®le 3D CNN ---\")\n",
    "    \n",
    "    # [cite_start]Image Augmentation (Optionnel - Si ImageDataGenerator peut √™tre adapt√© √† la 3D) [cite: 68]\n",
    "    # Note: Keras ImageDataGenerator est principalement pour la 2D. \n",
    "    # Une augmentation 3D n√©cessiterait une impl√©mentation personnalis√©e.\n",
    "    \n",
    "    model.fit(\n",
    "        X_train_resampled, \n",
    "        y_train_resampled_one_hot,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=(X_test, y_test_one_hot),\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # 6. √âvaluation Finale (Error Metrics - Section 18)\n",
    "    loss, acc, rec = model.evaluate(X_test, y_test_one_hot, verbose=0)\n",
    "    \n",
    "    print(f\"\\nR√©sultats sur l'ensemble de test (post-pr√©traitement):\")\n",
    "    print(f\"  Pr√©cision (Accuracy): {acc:.4f}\")\n",
    "    print(f\"  Sensibilit√© (Recall): {rec:.4f} (Critique pour la d√©tection pr√©coce)\")\n",
    "    \n",
    "    # Sauvegarde du mod√®le\n",
    "    model.save(\"alzheimer_3d_cnn_final.keras\")\n",
    "    print(\"\\nMod√®le sauvegard√©.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9749efa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installer nibabel si nécessaire (exécuter dans la cellule Jupyter)\n",
    "%pip install nibabel\n",
    "\n",
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE  # Pour la gestion des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370311d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 0. PARAMÈTRES ET CHEMINS\n",
    "# ==============================================================================\n",
    "\n",
    "# Dossier Racine contenant les sous-dossiers de classes (MildDemented, NonDemented, etc.)\n",
    "DATA_ROOT_DIR = 'C:\\\\Users\\\\angej\\\\Desktop\\\\Advancing Alzheimer’s Disease Detection in Clinical Settings MRI Image Data\\\\Advancing Alzheimer’s Disease Detection in Clinical Settings MRI Image Data\\\\Alzheimer_s Dataset\\\\train' \n",
    "\n",
    "# Paramètres de l'image et du modèle\n",
    "IMAGE_SIZE = (128, 128)  # Redimensionnement des images (Section 12: Resizing Images)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Les classes sont définies par vos noms de dossiers (image_59df9b.png)\n",
    "CLASS_NAMES = ['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented']\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "# Définir l'ordre des classes si nécessaire pour l'interprétation des résultats\n",
    "# Keras chargera les classes par ordre alphanumérique, donc vérifiez l'ordre réel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2865d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Le dossier racine de votre ensemble d'entraînement (contient les dossiers de classes)\n",
    "DATA_ROOT_DIR = 'path/to/votre/dossier/train' \n",
    "\n",
    "# Les noms de vos dossiers (classes)\n",
    "CLASS_NAMES = ['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented']\n",
    "\n",
    "def plot_class_distribution(data_dir, classes):\n",
    "    \"\"\"Calcule et affiche la distribution des classes.\"\"\"\n",
    "    counts = {}\n",
    "    for cls in classes:\n",
    "        cls_path = os.path.join(data_dir, cls)\n",
    "        # Compte le nombre de fichiers .jpg dans chaque dossier\n",
    "        if os.path.isdir(cls_path):\n",
    "            count = len([name for name in os.listdir(cls_path) if name.endswith(('.jpg', '.jpeg', '.png'))])\n",
    "            counts[cls] = count\n",
    "        else:\n",
    "            counts[cls] = 0\n",
    "    \n",
    "    df_counts = pd.DataFrame(list(counts.items()), columns=['Class', 'Count']).sort_values(by='Count', ascending=False)\n",
    "    \n",
    "    print(\"Distribution des Classes:\\n\", df_counts)\n",
    "    \n",
    "    # Visualisation\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(df_counts['Class'], df_counts['Count'], color=['skyblue', 'salmon', 'lightgreen', 'gold'])\n",
    "    plt.title('Distribution du Nombre d\\'Images par Classe de Démence')\n",
    "    plt.xlabel('Stade de Démence')\n",
    "    plt.ylabel('Nombre d\\'Images')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# plot_class_distribution(DATA_ROOT_DIR, CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758790ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "# I. FONCTIONS DE PRÉ-TRAITEMENT ET CHARGEMENT DES DONNÉES\n",
    "# ==============================================================================\n",
    "\n",
    "def load_data_from_directory(directory, subset_name=None, seed=None):\n",
    "    \"\"\"\n",
    "    Charge les images depuis les dossiers. Gère le redimensionnement, \n",
    "    et la normalisation (image / 255.0 - Section 12).\n",
    "    \"\"\"\n",
    "    if subset_name:\n",
    "        print(f\"Chargement du sous-ensemble: {subset_name}\")\n",
    "\n",
    "    # Le label_mode='categorical' applique le One-Hot Encoding (Section 3)\n",
    "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "        directory,\n",
    "        labels='inferred',\n",
    "        label_mode='categorical',\n",
    "        class_names=CLASS_NAMES,\n",
    "        image_size=IMAGE_SIZE,\n",
    "        interpolation='bilinear',\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True if subset_name == 'training' else False,\n",
    "        seed=seed \n",
    "    )\n",
    "    \n",
    "    # Normaliser les valeurs de pixel (Section 12: Normalizing Pixel Values)\n",
    "    # L'intervalle de [0, 255] est mis à l'échelle à [0, 1]\n",
    "    normalization_layer = layers.Rescaling(1./255) \n",
    "    \n",
    "    return dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "\n",
    "def setup_data_generators(data_root_dir):\n",
    "    \"\"\"\n",
    "    Configure le split Train/Validation/Test et l'augmentation des données.\n",
    "    \"\"\"\n",
    "    # Étape 1: Séparer les données en Training et Test (Section 10)\n",
    "    # Nous utiliserons la séparation manuelle pour un contrôle total sur l'augmentation\n",
    "    \n",
    "    # Keras ne supporte pas nativement la Stratified Split sur les dossiers\n",
    "    # Il est recommandé de le faire manuellement ou d'utiliser une K-Fold manuelle.\n",
    "    # Pour la simplicité, nous allons utiliser un split direct Keras/TF.\n",
    "\n",
    "    # Chargement d'un grand ensemble pour le Training/Validation\n",
    "    train_ds = load_data_from_directory(DATA_ROOT_DIR, subset_name='training', seed=RANDOM_STATE)\n",
    "    \n",
    "    # Déterminer la taille pour le split Validation/Test\n",
    "    # Prenons 80% des données pour le train et 20% pour le test (split non-stratifié ici)\n",
    "    \n",
    "    # Pour un environnement réel, utiliser train_test_split (sklearn) après avoir \n",
    "    # listé tous les chemins d'accès pour garantir la stratification.\n",
    "    \n",
    "    # Utilisons ImageDataGenerator pour l'augmentation (Section 12: Image Augmentation)\n",
    "    # Ceci est appliqué uniquement à l'ensemble d'entraînement pour éviter la fuite de données.\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    # Comme image_dataset_from_directory charge déjà et normalise, nous allons\n",
    "    # Simplement utiliser les transformations de l'augmentation comme un layer Keras\n",
    "    # dans le modèle pour un pipeline plus moderne (voir fonction build_2d_cnn_model).\n",
    "    \n",
    "    # Note: Dans un scénario idéal, vous devriez utiliser StratifiedKFold (Section 10) \n",
    "    # pour garantir que chaque classe (surtout 'ModerateDemented' qui pourrait être petite) \n",
    "    # est bien représentée.\n",
    "    \n",
    "    return train_ds # Simplification: utilisez cet ensemble comme ensemble principal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e15f677",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "# II. DÉFINITION DU MODÈLE 2D CNN (VGG-like)\n",
    "# ==============================================================================\n",
    "\n",
    "def build_2d_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Construit une architecture 2D CNN simple (VGG-like) adaptée aux images JPEG.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Couche d'Augmentation (pour le Training seulement, appliquée avant le modèle)\n",
    "    data_augmentation = keras.Sequential(\n",
    "        [\n",
    "            layers.RandomFlip(\"horizontal\", seed=RANDOM_STATE),\n",
    "            layers.RandomRotation(0.1, seed=RANDOM_STATE),\n",
    "            layers.RandomZoom(0.1, seed=RANDOM_STATE),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Appliquer l'augmentation uniquement si ce n'est pas la validation/test\n",
    "    x = data_augmentation(inputs) \n",
    "    \n",
    "    # Standardisation Z-Score (Section 2 - Data Transformation) peut être réappliquée ici si besoin\n",
    "    # mean_std_layer = layers.Normalization() \n",
    "    # x = mean_std_layer(x) \n",
    "\n",
    "    # Blocs de Convolution 2D\n",
    "    \n",
    "    x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    \n",
    "    x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    \n",
    "    x = layers.Conv2D(128, 3, activation='relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    \n",
    "    # Classification\n",
    "    x = layers.GlobalAveragePooling2D()(x) \n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x) # Section 33: Dropout (Technique d'évitement du surapprentissage)\n",
    "    \n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs, name=\"2dcnn_alzheimer\")\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy', keras.metrics.Recall(name='recall')] # Rappel/Sensibilité pour la détection précoce\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# ==============================================================================\n",
    "# III. EXÉCUTION DU PIPELINE\n",
    "# ==============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(\"--- 🧠 Pipeline de classification 2D Alzheimer (JPEG) 🧠 ---\")\n",
    "\n",
    "    # Vérifiez si le dossier existe\n",
    "    if not os.path.isdir(DATA_ROOT_DIR):\n",
    "        print(f\"Erreur: Le dossier racine '{DATA_ROOT_DIR}' n'existe pas. Veuillez le mettre à jour.\")\n",
    "    else:\n",
    "        # 1. Chargement des données et Pré-traitement\n",
    "        \n",
    "        # NOTE: Nous allons simuler un split train/validation/test ici.\n",
    "        # En réalité, vos données devraient être dans des dossiers train/val/test séparés.\n",
    "        \n",
    "        train_ds = load_data_from_directory(DATA_ROOT_DIR, subset_name='training', seed=RANDOM_STATE).take(int(0.8 * len(os.listdir(DATA_ROOT_DIR))))\n",
    "        val_ds = load_data_from_directory(DATA_ROOT_DIR, subset_name='validation', seed=RANDOM_STATE).skip(int(0.8 * len(os.listdir(DATA_ROOT_DIR))))\n",
    "\n",
    "        # 2. Gestion des Données Déséquilibrées (Dealing with Imbalanced Data - Section 14)\n",
    "        # Pour les datasets chargés directement (image_dataset_from_directory), la meilleure \n",
    "        # technique est souvent la pondération des classes ou le sur-échantillonnage \n",
    "        # pendant l'entraînement, car SMOTE (Section 14) est difficile à appliquer directement \n",
    "        # sur les générateurs de données Keras sans les matérialiser en mémoire.\n",
    "        \n",
    "        # Calcul des pondérations de classe pour l'exemple (très important ici)\n",
    "        print(\"\\nCalcul des poids de classe (pour gérer le déséquilibre)...\")\n",
    "        # Un calcul réel nécessiterait de parcourir l'ensemble de données complet\n",
    "        class_counts = {\n",
    "            'NonDemented': 2560, # Simuler un grand nombre\n",
    "            'VeryMildDemented': 1792,\n",
    "            'MildDemented': 896,\n",
    "            'ModerateDemented': 64 # Simuler la classe la plus petite\n",
    "        }\n",
    "        total_samples = sum(class_counts.values())\n",
    "        max_count = max(class_counts.values())\n",
    "        \n",
    "        # Pondération: inversement proportionnelle à la fréquence\n",
    "        class_weights = {\n",
    "            CLASS_NAMES.index(cls): max_count / count \n",
    "            for cls, count in class_counts.items()\n",
    "        }\n",
    "        print(f\"Poids de classe ajustés (pour le paramètre class_weight): {class_weights}\")\n",
    "\n",
    "\n",
    "        # 3. Entraînement du Modèle\n",
    "        \n",
    "        input_shape = (*IMAGE_SIZE, 3) # Les images JPG ont 3 canaux (RGB)\n",
    "        model = build_2d_cnn_model(input_shape, NUM_CLASSES)\n",
    "        model.summary()\n",
    "\n",
    "        print(\"\\n--- Entraînement du modèle 2D CNN ---\")\n",
    "        \n",
    "        # Utiliser les poids de classe pour compenser le déséquilibre\n",
    "        history = model.fit(\n",
    "            train_ds,\n",
    "            validation_data=val_ds,\n",
    "            epochs=EPOCHS,\n",
    "            class_weight=class_weights, # Appliquer la pondération ici\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # 4. Évaluation Finale\n",
    "        print(\"\\n--- Évaluation finale du modèle ---\")\n",
    "        # Note: L'ensemble de validation (val_ds) sert d'évaluation ici.\n",
    "        \n",
    "        loss, acc, rec = model.evaluate(val_ds, verbose=0)\n",
    "        \n",
    "        print(f\"Résultats sur l'ensemble de validation:\")\n",
    "        print(f\"  Précision (Accuracy): {acc:.4f}\")\n",
    "        print(f\"  Sensibilité (Recall): {rec:.4f} (Critique pour la détection précoce)\")\n",
    "        \n",
    "        # Sauvegarde\n",
    "        model.save(\"alzheimer_2d_cnn_final.keras\")\n",
    "        print(\"\\nModèle sauvegardé.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acb1e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "# 0. PARAMÈTRES ET SIMULATION DES DONNÉES\n",
    "# ==============================================================================\n",
    "\n",
    "# NOTE: REMPLACER CES CHEMINS PAR LES VÔTRES\n",
    "IMAGE_DIR = 'data/images/'\n",
    "LABELS_FILE = 'data/labels.csv'\n",
    "\n",
    "# Paramètres du modèle et du prétraitement\n",
    "IMAGE_SIZE = (64, 64, 64) # Taille cible des volumes (compromis entre performance et VRAM)\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 10 \n",
    "K_FOLDS = 5 # Pour la validation croisée stratifiée\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Simulation de la base de données (si non disponible)\n",
    "# df = pd.DataFrame({\n",
    "#     'ID': [f'sujet_{i:03d}' for i in range(100)],\n",
    "#     'Groupe': np.random.choice(['CN', 'MCI', 'AD'], \n",
    "#                                size=100, \n",
    "#                                p=[0.7, 0.2, 0.1]) # Classes déséquilibrées\n",
    "# })\n",
    "# df.to_csv(LABELS_FILE, index=False)\n",
    "# print(\"Simulation des données terminée.\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# I. FONCTIONS DE PRÉ-TRAITEMENT DES IMAGES\n",
    "# (S'inspire des sections 12 et 13 du TP)\n",
    "# ==============================================================================\n",
    "\n",
    "def load_and_preprocess_mri(file_path, target_size, method='z_score'):\n",
    "    \"\"\"\n",
    "    Charge une image 3D (NIfTI), applique la Normalisation (Z-Score ou Min-Max)\n",
    "    et le Redimensionnement (Resizing).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = nib.load(file_path)\n",
    "        data = img.get_fdata()\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur de chargement pour {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Normalisation de l'intensité (Section 2 - Data Transformation)\n",
    "    if method == 'z_score':\n",
    "        # [cite_start]Standardization (Z-Score Normalization) [cite: 13]\n",
    "        mean = np.mean(data)\n",
    "        std = np.std(data)\n",
    "        data = (data - mean) / (std + 1e-6)  # Ajout de 1e-6 pour éviter division par zéro\n",
    "    elif method == 'min_max':\n",
    "        # [cite_start]Min-Max Normalization (similaire à image / 255.0) [cite: 14, 67]\n",
    "        min_val = np.min(data)\n",
    "        max_val = np.max(data)\n",
    "        data = (data - min_val) / (max_val - min_val + 1e-6)\n",
    "\n",
    "    # [cite_start]Redimensionnement (Resizing Images - Section 12) [cite: 66]\n",
    "    # Redimensionnement 3D vers la taille cible\n",
    "    data = tf.image.resize(\n",
    "        np.expand_dims(data, axis=-1), \n",
    "        target_size, \n",
    "        method='nearest' # Ou 'trilinear' pour une meilleure qualité\n",
    "    ).numpy()\n",
    "    \n",
    "    # Retourne le volume sans la dimension de canal, en float32\n",
    "    return data.squeeze().astype(np.float32)\n",
    "\n",
    "def image_data_generator(df, image_dir, target_size, encoder):\n",
    "    \"\"\"\n",
    "    Générateur de données pour charger et prétraiter toutes les images \n",
    "    en mémoire pour la phase d'entraînement (utile pour SMOTE).\n",
    "    \"\"\"\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    \n",
    "    print(f\"Chargement et prétraitement de {len(df)} images...\")\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        file_path = os.path.join(image_dir, row['ID'] + '.nii.gz') # Adapter l'extension si nécessaire\n",
    "        \n",
    "        image_data = load_and_preprocess_mri(file_path, target_size, method='z_score')\n",
    "        \n",
    "        if image_data is not None:\n",
    "            # Ajouter la dimension du canal (1) pour le 3D CNN\n",
    "            X_list.append(np.expand_dims(image_data, axis=-1))\n",
    "            y_list.append(row['Groupe_Encoded'])\n",
    "            \n",
    "    return np.array(X_list), np.array(y_list)\n",
    "\n",
    "# ==============================================================================\n",
    "# II. DÉFINITION DU MODÈLE 3D CNN ET ENTRAÎNEMENT\n",
    "# ==============================================================================\n",
    "\n",
    "def build_3d_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Construit une architecture 3D CNN simple pour la classification.\n",
    "    \"\"\"\n",
    "    inputs = keras.Input(input_shape)\n",
    "\n",
    "    # Couche 1\n",
    "    x = layers.Conv3D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x) \n",
    "\n",
    "    # Couche 2\n",
    "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # Couche de classification\n",
    "    x = layers.GlobalAveragePooling3D()(x) \n",
    "    x = layers.Dense(units=128, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x) \n",
    "\n",
    "    outputs = layers.Dense(units=num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs, name=\"3dcnn_alzheimer\")\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        metrics=[\"accuracy\", keras.metrics.Recall(name='recall')]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# III. EXÉCUTION DU PIPELINE (AVEC GESTION DE DÉSÉQUILIBRE)\n",
    "# ==============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(\"--- 🧠 Début du pipeline de détection précoce Alzheimer 🧠 ---\")\n",
    "\n",
    "    # 1. Chargement et Encodage des Étiquettes\n",
    "    df = pd.read_csv(LABELS_FILE)\n",
    "    \n",
    "    # Nettoyage des données (Handling Missing Values - Section 1)\n",
    "    [cite_start]df.dropna(subset=['Groupe'], inplace=True) # Supprimer les lignes sans étiquette [cite: 7]\n",
    "    \n",
    "    # Encodage des étiquettes (Feature Encoding - Section 3)\n",
    "    # Ex: CN -> 0, MCI -> 1, AD -> 2\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['Groupe_Encoded'] = label_encoder.fit_transform(df['Groupe'])\n",
    "    NUM_CLASSES = len(label_encoder.classes_)\n",
    "    \n",
    "    print(f\"Classes: {list(label_encoder.classes_)}\")\n",
    "    print(df['Groupe'].value_counts())\n",
    "    \n",
    "    # 2. Séparation des données (Data Splitting - Section 10)\n",
    "    # [cite_start]Séparation stratifiée pour conserver la proportion des classes dans les ensembles [cite: 58]\n",
    "    train_df, test_df = train_test_split(\n",
    "        df, \n",
    "        test_size=0.2, \n",
    "        random_state=RANDOM_STATE, \n",
    "        stratify=df['Groupe_Encoded']\n",
    "    )\n",
    "    \n",
    "    # 3. Chargement et Prétraitement des Volumes\n",
    "    # Nous chargeons toutes les données d'entraînement pour appliquer SMOTE après.\n",
    "    X_train_raw, y_train_encoded = image_data_generator(train_df, IMAGE_DIR, IMAGE_SIZE, label_encoder)\n",
    "    X_test, y_test_encoded = image_data_generator(test_df, IMAGE_DIR, IMAGE_SIZE, label_encoder)\n",
    "    \n",
    "    # [cite_start]Conversion One-Hot pour le modèle (Sequence Data Processing - Section 21) [cite: 105]\n",
    "    y_test_one_hot = keras.utils.to_categorical(y_test_encoded, num_classes=NUM_CLASSES)\n",
    "    \n",
    "    # 4. Gestion des Données Déséquilibrées (Dealing with Imbalanced Data - Section 14)\n",
    "    # SMOTE nécessite que les données d'image soient \"aplaties\" temporairement\n",
    "    # SMOTE n'est pas idéal pour les données d'image haute dimension, mais il est listé.\n",
    "    print(\"\\n--- Application de SMOTE pour l'équilibrage des classes ---\")\n",
    "    \n",
    "    # Aplatir les images (D*H*W*C) -> (N, D*H*W*C)\n",
    "    X_train_flat = X_train_raw.reshape(X_train_raw.shape[0], -1) \n",
    "    \n",
    "    # [cite_start]Application de SMOTE [cite: 76]\n",
    "    # Ceci va sur-échantillonner les classes MCI et AD (moins représentées)\n",
    "    smote = SMOTE(random_state=RANDOM_STATE) \n",
    "    X_train_resampled_flat, y_train_resampled_encoded = smote.fit_resample(X_train_flat, y_train_encoded)\n",
    "    \n",
    "    # Re-former les images (N, D*H*W*C) -> (N, D, H, W, C)\n",
    "    X_train_resampled = X_train_resampled_flat.reshape(\n",
    "        (len(X_train_resampled_flat), *IMAGE_SIZE, 1)\n",
    "    )\n",
    "    y_train_resampled_one_hot = keras.utils.to_categorical(\n",
    "        y_train_resampled_encoded, num_classes=NUM_CLASSES\n",
    "    )\n",
    "\n",
    "    print(\"Distribution après SMOTE:\\n\", pd.Series(y_train_resampled_encoded).value_counts())\n",
    "\n",
    "    # 5. Entraînement du Modèle\n",
    "    input_shape = (*IMAGE_SIZE, 1) \n",
    "    model = build_3d_cnn_model(input_shape, NUM_CLASSES)\n",
    "    \n",
    "    print(\"\\n--- Entraînement du modèle 3D CNN ---\")\n",
    "    \n",
    "    # [cite_start]Image Augmentation (Optionnel - Si ImageDataGenerator peut être adapté à la 3D) [cite: 68]\n",
    "    # Note: Keras ImageDataGenerator est principalement pour la 2D. \n",
    "    # Une augmentation 3D nécessiterait une implémentation personnalisée.\n",
    "    \n",
    "    model.fit(\n",
    "        X_train_resampled, \n",
    "        y_train_resampled_one_hot,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=(X_test, y_test_one_hot),\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # 6. Évaluation Finale (Error Metrics - Section 18)\n",
    "    loss, acc, rec = model.evaluate(X_test, y_test_one_hot, verbose=0)\n",
    "    \n",
    "    print(f\"\\nRésultats sur l'ensemble de test (post-prétraitement):\")\n",
    "    print(f\"  Précision (Accuracy): {acc:.4f}\")\n",
    "    print(f\"  Sensibilité (Recall): {rec:.4f} (Critique pour la détection précoce)\")\n",
    "    \n",
    "    # Sauvegarde du modèle\n",
    "    model.save(\"alzheimer_3d_cnn_final.keras\")\n",
    "    print(\"\\nModèle sauvegardé.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
